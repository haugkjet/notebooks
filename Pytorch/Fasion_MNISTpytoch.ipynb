{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd12cb48-de7d-47ad-b5b5-9f29ff3c665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74d908b2-3bac-4c2b-a7fc-78cbc427ffa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c5c4c8cd8d4a9a82b3ef16603c38c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916c68938e624aeaab0e5674fa204e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d43e3d2cc0744c9b9399e495d8a18c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9304fb0464e8455694a88b48b6cb5a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root =\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "657b0d2e-f128-40d9-b200-b865c2425f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69cd8290-013a-43d3-a4e1-529849a2f869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X[N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader=DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader=DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X[N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69088668-29f1-46ff-9948-9479d3f2ad50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "989af92f-fe20-47fd-bbee-3f674b1f0629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "        \n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec5476e2-87d2-4ae1-a613-4cd012051ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "617f487c-4466-40b8-8f5c-55b1c7d5ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate (dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:5d}|{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaf3be33-cd0e-41cd-a52f-8e44609d9d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size =  len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0 , 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "                                                  \n",
    "                                                  \n",
    "                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64895727-980a-48d3-8485-c76eb399ec21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/n------------------------\n",
      "loss: 0.229822 [    0|60000]\n",
      "loss: 0.374555 [ 6400|60000]\n",
      "loss: 0.236439 [12800|60000]\n",
      "loss: 0.392591 [19200|60000]\n",
      "loss: 0.319688 [25600|60000]\n",
      "loss: 0.381590 [32000|60000]\n",
      "loss: 0.361879 [38400|60000]\n",
      "loss: 0.500919 [44800|60000]\n",
      "loss: 0.459382 [51200|60000]\n",
      "loss: 0.369874 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.409557 \n",
      "\n",
      "Epoch 2/n------------------------\n",
      "loss: 0.225977 [    0|60000]\n",
      "loss: 0.368939 [ 6400|60000]\n",
      "loss: 0.232700 [12800|60000]\n",
      "loss: 0.385626 [19200|60000]\n",
      "loss: 0.315408 [25600|60000]\n",
      "loss: 0.375626 [32000|60000]\n",
      "loss: 0.356034 [38400|60000]\n",
      "loss: 0.494883 [44800|60000]\n",
      "loss: 0.451984 [51200|60000]\n",
      "loss: 0.368140 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.405173 \n",
      "\n",
      "Epoch 3/n------------------------\n",
      "loss: 0.222430 [    0|60000]\n",
      "loss: 0.363934 [ 6400|60000]\n",
      "loss: 0.229664 [12800|60000]\n",
      "loss: 0.378530 [19200|60000]\n",
      "loss: 0.310502 [25600|60000]\n",
      "loss: 0.369411 [32000|60000]\n",
      "loss: 0.350591 [38400|60000]\n",
      "loss: 0.487685 [44800|60000]\n",
      "loss: 0.444525 [51200|60000]\n",
      "loss: 0.366292 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.401227 \n",
      "\n",
      "Epoch 4/n------------------------\n",
      "loss: 0.218766 [    0|60000]\n",
      "loss: 0.359127 [ 6400|60000]\n",
      "loss: 0.227239 [12800|60000]\n",
      "loss: 0.372116 [19200|60000]\n",
      "loss: 0.307039 [25600|60000]\n",
      "loss: 0.364202 [32000|60000]\n",
      "loss: 0.344723 [38400|60000]\n",
      "loss: 0.480726 [44800|60000]\n",
      "loss: 0.438230 [51200|60000]\n",
      "loss: 0.363084 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.397222 \n",
      "\n",
      "Epoch 5/n------------------------\n",
      "loss: 0.215589 [    0|60000]\n",
      "loss: 0.354050 [ 6400|60000]\n",
      "loss: 0.224024 [12800|60000]\n",
      "loss: 0.366171 [19200|60000]\n",
      "loss: 0.303654 [25600|60000]\n",
      "loss: 0.359598 [32000|60000]\n",
      "loss: 0.340083 [38400|60000]\n",
      "loss: 0.473238 [44800|60000]\n",
      "loss: 0.432379 [51200|60000]\n",
      "loss: 0.361965 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.393480 \n",
      "\n",
      "Epoch 6/n------------------------\n",
      "loss: 0.213705 [    0|60000]\n",
      "loss: 0.349781 [ 6400|60000]\n",
      "loss: 0.221589 [12800|60000]\n",
      "loss: 0.360109 [19200|60000]\n",
      "loss: 0.300078 [25600|60000]\n",
      "loss: 0.356293 [32000|60000]\n",
      "loss: 0.336450 [38400|60000]\n",
      "loss: 0.465779 [44800|60000]\n",
      "loss: 0.426469 [51200|60000]\n",
      "loss: 0.359495 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.389464 \n",
      "\n",
      "Epoch 7/n------------------------\n",
      "loss: 0.210202 [    0|60000]\n",
      "loss: 0.345680 [ 6400|60000]\n",
      "loss: 0.218274 [12800|60000]\n",
      "loss: 0.354564 [19200|60000]\n",
      "loss: 0.295973 [25600|60000]\n",
      "loss: 0.351147 [32000|60000]\n",
      "loss: 0.332010 [38400|60000]\n",
      "loss: 0.459956 [44800|60000]\n",
      "loss: 0.419830 [51200|60000]\n",
      "loss: 0.356985 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.385957 \n",
      "\n",
      "Epoch 8/n------------------------\n",
      "loss: 0.207022 [    0|60000]\n",
      "loss: 0.341427 [ 6400|60000]\n",
      "loss: 0.215634 [12800|60000]\n",
      "loss: 0.348251 [19200|60000]\n",
      "loss: 0.291763 [25600|60000]\n",
      "loss: 0.347579 [32000|60000]\n",
      "loss: 0.327270 [38400|60000]\n",
      "loss: 0.454012 [44800|60000]\n",
      "loss: 0.412343 [51200|60000]\n",
      "loss: 0.355557 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.382330 \n",
      "\n",
      "Epoch 9/n------------------------\n",
      "loss: 0.203797 [    0|60000]\n",
      "loss: 0.336550 [ 6400|60000]\n",
      "loss: 0.212749 [12800|60000]\n",
      "loss: 0.342353 [19200|60000]\n",
      "loss: 0.288264 [25600|60000]\n",
      "loss: 0.343698 [32000|60000]\n",
      "loss: 0.323253 [38400|60000]\n",
      "loss: 0.447610 [44800|60000]\n",
      "loss: 0.405601 [51200|60000]\n",
      "loss: 0.353188 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.379049 \n",
      "\n",
      "Epoch 10/n------------------------\n",
      "loss: 0.202218 [    0|60000]\n",
      "loss: 0.332330 [ 6400|60000]\n",
      "loss: 0.209391 [12800|60000]\n",
      "loss: 0.337291 [19200|60000]\n",
      "loss: 0.284840 [25600|60000]\n",
      "loss: 0.340005 [32000|60000]\n",
      "loss: 0.319909 [38400|60000]\n",
      "loss: 0.441600 [44800|60000]\n",
      "loss: 0.398970 [51200|60000]\n",
      "loss: 0.351387 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.376450 \n",
      "\n",
      "Epoch 11/n------------------------\n",
      "loss: 0.199702 [    0|60000]\n",
      "loss: 0.330697 [ 6400|60000]\n",
      "loss: 0.206744 [12800|60000]\n",
      "loss: 0.332531 [19200|60000]\n",
      "loss: 0.283389 [25600|60000]\n",
      "loss: 0.335607 [32000|60000]\n",
      "loss: 0.316402 [38400|60000]\n",
      "loss: 0.436347 [44800|60000]\n",
      "loss: 0.392006 [51200|60000]\n",
      "loss: 0.348945 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.373426 \n",
      "\n",
      "Epoch 12/n------------------------\n",
      "loss: 0.198868 [    0|60000]\n",
      "loss: 0.328658 [ 6400|60000]\n",
      "loss: 0.205218 [12800|60000]\n",
      "loss: 0.326180 [19200|60000]\n",
      "loss: 0.282237 [25600|60000]\n",
      "loss: 0.333305 [32000|60000]\n",
      "loss: 0.312208 [38400|60000]\n",
      "loss: 0.431359 [44800|60000]\n",
      "loss: 0.386119 [51200|60000]\n",
      "loss: 0.347125 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.371437 \n",
      "\n",
      "Epoch 13/n------------------------\n",
      "loss: 0.197708 [    0|60000]\n",
      "loss: 0.325264 [ 6400|60000]\n",
      "loss: 0.202976 [12800|60000]\n",
      "loss: 0.320256 [19200|60000]\n",
      "loss: 0.281599 [25600|60000]\n",
      "loss: 0.331238 [32000|60000]\n",
      "loss: 0.310023 [38400|60000]\n",
      "loss: 0.424683 [44800|60000]\n",
      "loss: 0.379543 [51200|60000]\n",
      "loss: 0.345005 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.369225 \n",
      "\n",
      "Epoch 14/n------------------------\n",
      "loss: 0.197156 [    0|60000]\n",
      "loss: 0.321744 [ 6400|60000]\n",
      "loss: 0.200296 [12800|60000]\n",
      "loss: 0.315679 [19200|60000]\n",
      "loss: 0.280291 [25600|60000]\n",
      "loss: 0.329437 [32000|60000]\n",
      "loss: 0.306246 [38400|60000]\n",
      "loss: 0.417201 [44800|60000]\n",
      "loss: 0.372342 [51200|60000]\n",
      "loss: 0.342106 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.366824 \n",
      "\n",
      "Epoch 15/n------------------------\n",
      "loss: 0.196362 [    0|60000]\n",
      "loss: 0.318312 [ 6400|60000]\n",
      "loss: 0.198099 [12800|60000]\n",
      "loss: 0.309778 [19200|60000]\n",
      "loss: 0.279593 [25600|60000]\n",
      "loss: 0.327060 [32000|60000]\n",
      "loss: 0.302793 [38400|60000]\n",
      "loss: 0.410515 [44800|60000]\n",
      "loss: 0.365559 [51200|60000]\n",
      "loss: 0.338833 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.364777 \n",
      "\n",
      "Epoch 16/n------------------------\n",
      "loss: 0.194395 [    0|60000]\n",
      "loss: 0.315022 [ 6400|60000]\n",
      "loss: 0.195318 [12800|60000]\n",
      "loss: 0.304822 [19200|60000]\n",
      "loss: 0.277101 [25600|60000]\n",
      "loss: 0.323967 [32000|60000]\n",
      "loss: 0.300727 [38400|60000]\n",
      "loss: 0.402793 [44800|60000]\n",
      "loss: 0.358685 [51200|60000]\n",
      "loss: 0.337479 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.362364 \n",
      "\n",
      "Epoch 17/n------------------------\n",
      "loss: 0.193184 [    0|60000]\n",
      "loss: 0.312318 [ 6400|60000]\n",
      "loss: 0.193002 [12800|60000]\n",
      "loss: 0.300101 [19200|60000]\n",
      "loss: 0.277423 [25600|60000]\n",
      "loss: 0.320517 [32000|60000]\n",
      "loss: 0.297216 [38400|60000]\n",
      "loss: 0.397463 [44800|60000]\n",
      "loss: 0.352807 [51200|60000]\n",
      "loss: 0.335607 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.359458 \n",
      "\n",
      "Epoch 18/n------------------------\n",
      "loss: 0.192055 [    0|60000]\n",
      "loss: 0.308289 [ 6400|60000]\n",
      "loss: 0.191016 [12800|60000]\n",
      "loss: 0.294702 [19200|60000]\n",
      "loss: 0.275271 [25600|60000]\n",
      "loss: 0.318160 [32000|60000]\n",
      "loss: 0.294124 [38400|60000]\n",
      "loss: 0.390801 [44800|60000]\n",
      "loss: 0.347274 [51200|60000]\n",
      "loss: 0.332076 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.357350 \n",
      "\n",
      "Epoch 19/n------------------------\n",
      "loss: 0.191137 [    0|60000]\n",
      "loss: 0.305381 [ 6400|60000]\n",
      "loss: 0.188780 [12800|60000]\n",
      "loss: 0.289630 [19200|60000]\n",
      "loss: 0.275423 [25600|60000]\n",
      "loss: 0.314851 [32000|60000]\n",
      "loss: 0.291715 [38400|60000]\n",
      "loss: 0.385899 [44800|60000]\n",
      "loss: 0.340735 [51200|60000]\n",
      "loss: 0.331057 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.356117 \n",
      "\n",
      "Epoch 20/n------------------------\n",
      "loss: 0.192276 [    0|60000]\n",
      "loss: 0.301900 [ 6400|60000]\n",
      "loss: 0.187865 [12800|60000]\n",
      "loss: 0.285395 [19200|60000]\n",
      "loss: 0.275337 [25600|60000]\n",
      "loss: 0.312327 [32000|60000]\n",
      "loss: 0.289542 [38400|60000]\n",
      "loss: 0.380515 [44800|60000]\n",
      "loss: 0.335159 [51200|60000]\n",
      "loss: 0.326332 [57600|60000]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.354082 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for t in range (epochs):\n",
    "    print(f\"Epoch {t+1}/n------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc70fd7a-322a-4ba6-8989-d9b5bf395480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19691b90-6a6c-4290-b954-07e4df5ff702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
